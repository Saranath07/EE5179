{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sCs6JY8aLI_d"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NRSO56VjLLM9"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def cross_entropy(y_pred, y_true):\n",
        "    return -(y_true @ np.log(y_pred))\n",
        "\n",
        "def d_cross_entropy(y, y_pred):\n",
        "    return -(y - y_pred)\n",
        "\n",
        "def softmax(L):\n",
        "    arr = []\n",
        "    for i in L:\n",
        "        arr.append(np.exp(i) / np.exp(L).sum())\n",
        "\n",
        "    return arr\n",
        "\n",
        "def dsigmoid(x):\n",
        "    return sigmoid(x) * sigmoid(1- x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Dx5cPJmFLOCK"
      },
      "outputs": [],
      "source": [
        "def initialize_parameters(inputs, hidden_layers, outputs):\n",
        "    parameters = {}\n",
        "    parameters[\"W1\"] = np.random.rand(hidden_layers[0], inputs)\n",
        "    parameters[\"b1\"] = np.random.rand(hidden_layers[0])\n",
        "    for i in range(1, len(hidden_layers)):\n",
        "        parameters[f\"W{i+1}\"] = np.random.rand(hidden_layers[i], hidden_layers[i - 1])\n",
        "        parameters[f\"b{i+1}\"] = np.random.rand(hidden_layers[i])\n",
        "    parameters[f\"W{len(hidden_layers) + 1}\"] = np.random.rand(outputs, hidden_layers[-1])\n",
        "    parameters[f\"b{len(hidden_layers) + 1}\"] = np.random.rand(outputs)\n",
        "    return parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rx9ZnMzLQc3",
        "outputId": "3b3628dc-ae9f-4a25-fccb-9429988c21cb"
      },
      "outputs": [],
      "source": [
        "parameters = initialize_parameters(3, [3], 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkSTlAAxOq01"
      },
      "outputs": [],
      "source": [
        "W1 = np.array([\n",
        "    [0.5488135, 0.71518937, 0.60276338],\n",
        "    [0.54488318, 0.4236548, 0.64589411],\n",
        "    [0.43758721, 0.891773, 0.96366276]\n",
        "])\n",
        "W2 = np.array([\n",
        "    [0.56804456, 0.92559664, 0.07103606],\n",
        "    [0.0871293, 0.0202184, 0.83261985],\n",
        "    [0.77815675, 0.87001215, 0.97861834]\n",
        "])\n",
        "W3 = np.array([\n",
        "    [0.11827443, 0.63992102, 0.14335329],\n",
        "    [0.94466892, 0.52184832, 0.41466194],\n",
        "    [0.26455561, 0.77423369, 0.45615033]\n",
        "])\n",
        "\n",
        "b1 = np.array(\n",
        "    [0.38344152, 0.79172504, 0.52889492]\n",
        ")\n",
        "\n",
        "b2 = np.array(\n",
        "    [0.7991586, 0.46147936, 0.52889492]\n",
        ")\n",
        "\n",
        "b3 = np.array(\n",
        "    [0.56843395, 0.0187898, 0.6176355]\n",
        ")\n",
        "\n",
        "X = np.array(\n",
        "    [[1, 0, 1]]\n",
        ")\n",
        "\n",
        "Y = np.array(\n",
        "    [[0, 0, 1]]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMb9tv5oOmly"
      },
      "outputs": [],
      "source": [
        "parameters = {\n",
        "    'W1': W1,\n",
        "    'W2': W2,\n",
        "    'W3': W3,\n",
        "    'b1': b1,\n",
        "    'b2': b2,\n",
        "    'b3': b3,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VaqCXQ6bMvGa"
      },
      "outputs": [],
      "source": [
        "def forward_propogation(parameters, x, g, O):\n",
        "    activations = {}\n",
        "    activations[\"a1\"] = parameters[\"W1\"] @ x + parameters[\"b1\"]\n",
        "    activations[\"h1\"] = g(activations[\"a1\"])\n",
        "    for i in range(2, len(parameters) // 2):\n",
        "        activations[f\"a{i}\"] = parameters[f\"W{i}\"] @ activations[f\"h{i - 1}\"] + parameters[f\"b{i}\"]\n",
        "        activations[f\"h{i}\"] = g(activations[f\"a{i}\"])\n",
        "\n",
        "    activations[f\"a{len(parameters) // 2}\"] = parameters[f\"W{len(parameters) // 2}\"] @ activations[f\"h{len(parameters) // 2 - 1}\"] + parameters[f\"b{len(parameters) // 2}\"]\n",
        "    y_pred = O(activations[f\"a{len(parameters) // 2}\"])\n",
        "    return y_pred, activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = np.array(\n",
        "    [[1, 0, 1]]\n",
        ")\n",
        "\n",
        "Y = np.array(\n",
        "    [[0, 0, 1]]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgwYnxZ_Ov6d",
        "outputId": "c22ba179-67dc-4a1a-d0e4-e9e95261f05c"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 3)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mforward_propogation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigmoid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msoftmax\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[7], line 3\u001b[0m, in \u001b[0;36mforward_propogation\u001b[0;34m(parameters, x, g, O)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_propogation\u001b[39m(parameters, x, g, O):\n\u001b[1;32m      2\u001b[0m     activations \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 3\u001b[0m     activations[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mparameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mW1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m \u001b[38;5;241m+\u001b[39m parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m     activations[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m g(activations[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma1\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mlen\u001b[39m(parameters) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m):\n",
            "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 3)"
          ]
        }
      ],
      "source": [
        "forward_propogation(parameters, X, sigmoid, softmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08eIgLL1PZ7y"
      },
      "outputs": [],
      "source": [
        "def backPropogation(y_pred, y, activations, g_dash, O_dash, parameters, x):\n",
        "    losses = {}\n",
        "    n = len(parameters) // 2\n",
        "    m = len(activations) // 2\n",
        "    La = O_dash(y, y_pred)\n",
        "\n",
        "    Lh = La @ parameters[f\"W{n}\"]\n",
        "\n",
        "    da = g_dash(activations[f\"a{m}\"])\n",
        "    losses[f\"LW{n}\"] = np.outer(La, activations[f\"h{m}\"])\n",
        "    losses[f\"Lb{n}\"] = La.copy()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for i in range(1, m):\n",
        "        La = Lh * da\n",
        "        Lh = La @ parameters[f\"W{m - i + 1}\"]\n",
        "        da = g_dash(activations[f\"a{m - i}\"])\n",
        "        losses[f\"LW{m - i + 1}\"] = np.outer(La, activations[f\"h{m - i}\"])\n",
        "        losses[f\"Lb{m - i + 1}\"] = La.copy()\n",
        "\n",
        "    La = Lh * da\n",
        "    losses[\"LW1\"] = np.outer(La, x)\n",
        "    losses[\"Lb1\"] = La.copy()\n",
        "\n",
        "\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9J67lZeVk-t"
      },
      "outputs": [],
      "source": [
        "y_pred, activations = forward_propogation(parameters, x, sigmoid, softmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLaUMtvAVhki"
      },
      "outputs": [],
      "source": [
        "gradient_loss = backPropogation(y_pred, y, activations, dsigmoid, d_cross_entropy, parameters, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkMw_Texbr3U"
      },
      "outputs": [],
      "source": [
        "def gradient_descent(parameters, losses, eta):\n",
        "    new_parameters = {}\n",
        "    for i in range(len(parameters) // 2):\n",
        "        new_parameters[f\"W{i + 1}\"] = parameters[f\"W{i + 1}\"] - eta * losses[f\"LW{i + 1}\"]\n",
        "        new_parameters[f\"b{i + 1}\"] = parameters[f\"b{i + 1}\"] - eta * losses[f\"Lb{i + 1}\"]\n",
        "    return new_parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8840v0QcOWb"
      },
      "outputs": [],
      "source": [
        "new_parameters = gradient_descent(parameters, gradient_loss, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fN6xUPw7cmJR"
      },
      "outputs": [],
      "source": [
        "y_pred, activations = forward_propogation(new_parameters, x, sigmoid, softmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTd_XfnYczZu",
        "outputId": "6e5bb56f-5cf3-4ee3-adf9-893a7477f119"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.07711344018879235"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cross_entropy(y_pred, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpOpK0FFe__l"
      },
      "source": [
        "# Backpropogation code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Ag2iSrF_cmax"
      },
      "outputs": [],
      "source": [
        "from scipy.special import expit\n",
        "\n",
        "# Helper Functions\n",
        "def sigmoid(x):\n",
        "    return expit(x)\n",
        "\n",
        "def cross_entropy(y_pred, y_true, epsilon=1e-15):\n",
        "    # Clip y_pred to avoid values close to 0 or 1\n",
        "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
        "    return -(y_true @ np.log(y_pred))\n",
        "\n",
        "def d_cross_entropy(y, y_pred):\n",
        "    return -(y - y_pred)\n",
        "\n",
        "def softmax(L):\n",
        "    exp_L = np.exp(L - np.max(L))  # Subtract the maximum value to avoid overflow\n",
        "    return exp_L / exp_L.sum(axis=0, keepdims=True)  # Compute softmax along the specified axis\n",
        "\n",
        "def dsigmoid(x):\n",
        "    return sigmoid(x) * sigmoid(1- x)\n",
        "\n",
        "# Initialize Parameters\n",
        "\n",
        "def initialize_parameters(inputs, hidden_layers, outputs):\n",
        "    parameters = {}\n",
        "    parameters[\"W1\"] = np.random.rand(hidden_layers[0], inputs)\n",
        "    parameters[\"b1\"] = np.random.rand(hidden_layers[0])\n",
        "    for i in range(1, len(hidden_layers)):\n",
        "        parameters[f\"W{i+1}\"] = np.random.rand(hidden_layers[i], hidden_layers[i - 1])\n",
        "        parameters[f\"b{i+1}\"] = np.random.rand(hidden_layers[i])\n",
        "    parameters[f\"W{len(hidden_layers) + 1}\"] = np.random.rand(outputs, hidden_layers[-1])\n",
        "    parameters[f\"b{len(hidden_layers) + 1}\"] = np.random.rand(outputs)\n",
        "    return parameters\n",
        "\n",
        "# Forward Propogation\n",
        "\n",
        "def forward_propogation(parameters, x, g, O):\n",
        "    activations = {}\n",
        "\n",
        "    activations[\"a1\"] = parameters[\"W1\"] @ x + parameters[\"b1\"]\n",
        "    print(parameters[\"W1\"].shape, x.shape)\n",
        "    activations[\"h1\"] = g(activations[\"a1\"])\n",
        "    for i in range(2, len(parameters) // 2):\n",
        "        activations[f\"a{i}\"] = parameters[f\"W{i}\"] @ activations[f\"h{i - 1}\"] + parameters[f\"b{i}\"]\n",
        "        activations[f\"h{i}\"] = g(activations[f\"a{i}\"])\n",
        "\n",
        "    activations[f\"a{len(parameters) // 2}\"] = parameters[f\"W{len(parameters) // 2}\"] @ activations[f\"h{len(parameters) // 2 - 1}\"] + parameters[f\"b{len(parameters) // 2}\"]\n",
        "    y_pred = O(activations[f\"a{len(parameters) // 2}\"])\n",
        "    return y_pred, activations\n",
        "\n",
        "# Backpropogation\n",
        "\n",
        "def backPropogation(y_pred, y, activations, g_dash, O_dash, parameters, x):\n",
        "    losses = {}\n",
        "    n = len(parameters) // 2\n",
        "    m = len(activations) // 2\n",
        "    La = O_dash(y, y_pred)\n",
        "\n",
        "\n",
        "    Lh = La @ parameters[f\"W{n}\"]\n",
        "\n",
        "    da = g_dash(activations[f\"a{m}\"])\n",
        "    losses[f\"W{n}\"] = np.outer(La, activations[f\"h{m}\"])\n",
        "    losses[f\"b{n}\"] = La.copy()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for i in range(1, m):\n",
        "        La = Lh * da\n",
        "        Lh = La @ parameters[f\"W{m - i + 1}\"]\n",
        "        da = g_dash(activations[f\"a{m - i}\"])\n",
        "        losses[f\"W{m - i + 1}\"] = np.outer(La, activations[f\"h{m - i}\"])\n",
        "        losses[f\"b{m - i + 1}\"] = La.copy()\n",
        "\n",
        "    La = Lh * da\n",
        "    losses[\"W1\"] = np.outer(La, x)\n",
        "    losses[\"b1\"] = La.copy()\n",
        "\n",
        "\n",
        "    return losses\n",
        "\n",
        "# Gradient Descent (Batch)\n",
        "def gradient_descent(parameters, losses, eta):\n",
        "    for i in range(len(parameters) // 2):\n",
        "        parameters[f\"W{i + 1}\"] = parameters[f\"W{i + 1}\"] - eta * losses[f\"W{i + 1}\"]\n",
        "        parameters[f\"b{i + 1}\"] = parameters[f\"b{i + 1}\"] - eta * losses[f\"b{i + 1}\"]\n",
        "    return parameters\n",
        "\n",
        "def sgd(parameters, losses, eta):\n",
        "    new_parameters = {}\n",
        "    num_samples = len(losses)  # Number of data points or samples\n",
        "\n",
        "    # Iterate over each sample and update parameters using its corresponding gradient\n",
        "    for i in range(num_samples):\n",
        "        for j in range(1, len(parameters) // 2 + 1):  # Iterate over layers\n",
        "            new_parameters[f\"W{j}\"] = parameters[f\"W{j}\"] - eta * losses[f\"W{j}\"]\n",
        "            new_parameters[f\"b{j}\"] = parameters[f\"b{j}\"] - eta * losses[f\"b{j}\"]\n",
        "\n",
        "    return new_parameters\n",
        "\n",
        "\n",
        "def train(X, Y, epochs, hidden_layers, g, O, g_dash, O_dash, eta, optimizer):\n",
        "    parameters = initialize_parameters(X[0].shape[0], hidden_layers, Y[0].shape[0])\n",
        "    print(parameters)\n",
        "    for _ in range(epochs):\n",
        "        total_gradient_loss = {key: 0 for key in parameters.keys()}  # Initialize total gradient loss\n",
        "        for x, y in zip(X, Y):  # Iterate over each data point\n",
        "            y_pred, activations = forward_propogation(parameters, x, g, O)\n",
        "            gradient_loss = backPropogation(y_pred, y, activations, g_dash, O_dash, parameters, x)\n",
        "            # Accumulate the gradients for each data point\n",
        "            for key in total_gradient_loss:\n",
        "                total_gradient_loss[key] += gradient_loss.get(key, 0)\n",
        "        # Update the parameters using the accumulated gradients\n",
        "        parameters = optimizer(parameters, total_gradient_loss, eta)\n",
        "    return parameters\n",
        "\n",
        "def evaluate(X, parameters, g, O):\n",
        "    return np.array(forward_propogation(parameters, X, g, O)[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRZpWnjpc9jS",
        "outputId": "5fc01ff8-880a-4e48-9b49-f7819052ce55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'W1': array([[0.28869735, 0.23567597, 0.11877703],\n",
            "       [0.30184999, 0.87898168, 0.23652918],\n",
            "       [0.72732875, 0.83935795, 0.419922  ]]), 'b1': array([0.12565607, 0.26643362, 0.08139086]), 'W2': array([[0.38396647, 0.7600736 , 0.54402482],\n",
            "       [0.08819219, 0.5653798 , 0.66892124],\n",
            "       [0.01872262, 0.16715281, 0.0605212 ]]), 'b2': array([0.67908367, 0.20217154, 0.85491273])}\n"
          ]
        }
      ],
      "source": [
        "parameters = train(X, Y, 300, [3], sigmoid, softmax, dsigmoid, d_cross_entropy, 50, sgd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "sXRCUZao6S1b"
      },
      "outputs": [],
      "source": [
        "def initialize_parameters(inputs, hidden_layers, outputs):\n",
        "    parameters = {}\n",
        "    parameters[\"W1\"] = np.random.rand(hidden_layers[0], inputs)\n",
        "    parameters[\"b1\"] = np.random.rand(hidden_layers[0])\n",
        "    for i in range(1, len(hidden_layers)):\n",
        "        parameters[f\"W{i+1}\"] = np.random.rand(hidden_layers[i], hidden_layers[i - 1])\n",
        "        parameters[f\"b{i+1}\"] = np.random.rand(hidden_layers[i])\n",
        "    parameters[f\"W{len(hidden_layers) + 1}\"] = np.random.rand(outputs, hidden_layers[-1])\n",
        "    parameters[f\"b{len(hidden_layers) + 1}\"] = np.random.rand(outputs)\n",
        "\n",
        "    # Initialize AdaM parameters\n",
        "    v = {}\n",
        "    s = {}\n",
        "    for key in parameters.keys():\n",
        "        if key.startswith(\"W\") or key.startswith(\"b\"):\n",
        "            v[key] = np.zeros_like(parameters[key])\n",
        "            s[key] = np.zeros_like(parameters[key])\n",
        "\n",
        "    return parameters, v, s\n",
        "\n",
        "def adam(parameters, v, s, losses, eta, beta1=0.9, beta2=0.999, epsilon=1e-8, t=0):\n",
        "    for key in parameters.keys():\n",
        "        if key.startswith(\"W\") or key.startswith(\"b\"):\n",
        "            # Compute gradients\n",
        "            gradient = losses[key]\n",
        "\n",
        "            # Update time step\n",
        "            t += 1\n",
        "\n",
        "            # Update biased first moment estimate\n",
        "            v[key] = beta1 * v[key] + (1 - beta1) * gradient\n",
        "            # Update biased second moment estimate\n",
        "            s[key] = beta2 * s[key] + (1 - beta2) * (gradient ** 2)\n",
        "\n",
        "            # Correct the bias in the first moment\n",
        "            v_corrected = v[key] / (1 - beta1 ** t)\n",
        "            # Correct the bias in the second moment\n",
        "            s_corrected = s[key] / (1 - beta2 ** t)\n",
        "\n",
        "            # Update parameters\n",
        "            parameters[key] -= eta * v_corrected / (np.sqrt(s_corrected) + epsilon)\n",
        "\n",
        "    return parameters, v, s\n",
        "\n",
        "def train(X, Y, epochs, hidden_layers, g, O, g_dash, O_dash, eta, optimizer):\n",
        "    parameters, v, s = initialize_parameters(X[0].shape[0], hidden_layers, Y[0].shape[0])\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        for x, y in zip(X, Y):\n",
        "            y_pred, activations = forward_propogation(parameters, x, g, O)\n",
        "            gradient_loss = backPropogation(y_pred, y, activations, g_dash, O_dash, parameters, x)\n",
        "            parameters, v, s = optimizer(parameters, v, s, gradient_loss, eta)\n",
        "\n",
        "    return parameters\n",
        "\n",
        "# Usage example:\n",
        "# parameters = train(X, Y, epochs, hidden_layers, sigmoid, softmax, dsigmoid, d_cross_entropy, eta, adam)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "kVsGnCB2oHrQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "parameters = train(X, Y, 300, [3], sigmoid, softmax, dsigmoid, d_cross_entropy, 50, adam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AG3AXQk6475",
        "outputId": "0c011f3e-e761-4190-e95f-e604a5e16312"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'W1': array([[ 5.02904837e+02,  1.98871266e-01,  5.02161448e+02],\n",
              "        [-5.01262445e+02,  8.23084735e-02, -5.02013289e+02],\n",
              "        [ 5.03151126e+02,  6.26234032e-01,  5.02717998e+02]]),\n",
              " 'b1': array([ 373.53031037, -372.92542623,  374.33764426]),\n",
              " 'W2': array([[-320.82486349, -319.87119613, -320.78648288],\n",
              "        [-320.04887885, -319.91046457, -320.08023504],\n",
              "        [ 321.53481382,  321.53971701,  321.54160138]]),\n",
              " 'b2': array([-291.47668637, -290.92223191,  292.09833532])}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zN91cC74nKVX",
        "outputId": "5e4681e4-c67d-45e1-dfc1-1de71b7b9a64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((3,), (3,))"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0].shape, Y[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7OlYQ_heidr"
      },
      "outputs": [],
      "source": [
        "Y_pred = []\n",
        "for x in X:\n",
        "    y_pred = list(evaluate(x, parameters, sigmoid, softmax))\n",
        "    Y_pred.append(y_pred)\n",
        "Y_pred = np.array(Y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2DJnDXce6x9",
        "outputId": "04813a0c-f115-4c08-d462-05bab7a7d3ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[0, 0, 1]]), array([[0., 0., 1.]]))"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y, Y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUvZUBc5fyFy"
      },
      "source": [
        "# Testing phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDLEVE7Uf0cy",
        "outputId": "b1799b40-c53e-4d5e-e1af-5bd019185d1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (10, 10)\n",
            "Original y: [1 0 1 0 1 0 1 0 1 0]\n",
            "One-hot encoded y:\n",
            "[[0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]]\n"
          ]
        }
      ],
      "source": [
        "# import numpy as np\n",
        "\n",
        "# # Original data\n",
        "# y = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 0])\n",
        "\n",
        "# # Create X such that the index of the number of y is maximum in X\n",
        "# X = np.zeros((len(y), 10))  # Initialize X with zeros\n",
        "\n",
        "# beta = 0.85\n",
        "# for i in range(len(y)):\n",
        "#     max_index = y[i]  # Index of the number in y\n",
        "#     X[i, max_index] = beta  # Set the highest value in X\n",
        "#     X[i] += (1 - beta) / 9 # Add a small value to all elements to make sure they are not zero\n",
        "\n",
        "# print(\"X:\")\n",
        "# print(X)\n",
        "# print(\"Shape of X:\", X.shape)\n",
        "# print(\"y:\", y)\n",
        "# num_classes = 10\n",
        "# y_one_hot = np.eye(num_classes)[y]\n",
        "# y_one_hot\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "X = np.array([\n",
        "    [0.1, 0.5, 0.2, 0.9, 0.3, 0.6, 0.4, 0.8, 0.7, 0.2],\n",
        "    [0.3, 0.2, 0.7, 0.4, 0.6, 0.8, 0.9, 0.5, 0.1, 0.3],\n",
        "    [0.8, 0.9, 0.4, 0.1, 0.5, 0.2, 0.7, 0.6, 0.3, 0.9],\n",
        "    [0.6, 0.2, 0.3, 0.7, 0.4, 0.1, 0.8, 0.9, 0.5, 0.6],\n",
        "    [0.5, 0.1, 0.8, 0.2, 0.9, 0.7, 0.3, 0.4, 0.6, 0.5],\n",
        "    [0.7, 0.3, 0.6, 0.5, 0.8, 0.4, 0.1, 0.2, 0.9, 0.7],\n",
        "    [0.2, 0.8, 0.1, 0.6, 0.4, 0.5, 0.7, 0.3, 0.2, 0.8],\n",
        "    [0.9, 0.6, 0.5, 0.3, 0.7, 0.2, 0.4, 0.1, 0.8, 0.6],\n",
        "    [0.4, 0.7, 0.9, 0.8, 0.2, 0.3, 0.6, 0.5, 0.1, 0.4],\n",
        "    [0.5, 0.3, 0.7, 0.4, 0.1, 0.8, 0.2, 0.6, 0.7, 0.5]\n",
        "])\n",
        "\n",
        "y = np.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0])\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"Original y:\", y)\n",
        "\n",
        "# Convert y to one-hot encoded vectors\n",
        "num_classes = len(np.unique(y))\n",
        "y_one_hot = np.eye(num_classes)[y]\n",
        "\n",
        "print(\"One-hot encoded y:\")\n",
        "print(y_one_hot)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JGt69TcqWjf"
      },
      "outputs": [],
      "source": [
        "parameters = train(X, y_one_hot, 3000, [10], sigmoid, softmax, dsigmoid, d_cross_entropy, 0.01, adam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJEnY0jSgW1b",
        "outputId": "75b2dac0-0d3e-41e7-c017-44aabe4bfb6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'W1': array([[ -2.51072087,   6.19766604,   0.67532679,  -0.99178004,\n",
              "           4.26468957,  -1.61609701,  -5.57679556,   1.00271536,\n",
              "           1.64213245,   1.07632908],\n",
              "        [ -2.44288028,  -3.39721088,   2.04884379,  -7.6637196 ,\n",
              "           4.30587898,   1.2795474 ,  -4.59169589,   1.53730854,\n",
              "          -0.14477385,  -0.09671343],\n",
              "        [ -5.68646646,   2.71630869,   1.48319004,  -2.61143038,\n",
              "           5.52352841,   2.18021446,   4.77360728,   2.98010979,\n",
              "          -4.7730624 ,  -2.89451556],\n",
              "        [ -2.43524232,  -3.18139909,   1.45336449,  -7.33256972,\n",
              "           4.26204423,   1.40242954,  -4.66638533,   1.52323293,\n",
              "          -0.25857428,  -0.06945312],\n",
              "        [ -5.72020058,   3.42649823,   1.68299755,  -2.60292743,\n",
              "           5.22512958,   3.04507946,   3.69233077,   2.52104526,\n",
              "          -5.11112125,  -2.54772547],\n",
              "        [ -2.62817088,  -3.05082959,   1.91350118,  -7.32940427,\n",
              "           4.36178001,   0.64396745,  -4.49615928,   2.00979363,\n",
              "          -0.1294903 ,  -0.10844144],\n",
              "        [  5.12653362, -13.13274768,   3.12946753,  -2.97059151,\n",
              "           3.46644513,   3.43431984,   1.81993391,  -1.72915674,\n",
              "           2.88185112,  -0.16684408],\n",
              "        [  4.83354275, -12.22381946,   3.00692452,  -2.90834923,\n",
              "           2.7436232 ,   3.38385534,   2.36522744,  -1.94711017,\n",
              "           3.20573499,  -0.20580212],\n",
              "        [  4.77303745, -12.68035893,   3.07859246,  -2.83814183,\n",
              "           2.93390548,   3.18661049,   2.13494667,  -2.05296036,\n",
              "           3.0575825 ,  -0.04463465],\n",
              "        [  5.24835014, -13.74379764,   3.39955386,  -3.05414761,\n",
              "           3.30054766,   3.35264052,   2.02391156,  -1.74037215,\n",
              "           3.15129251,  -0.04007403]]),\n",
              " 'b1': array([0.37679624, 0.15501174, 0.85864855, 0.47304945, 0.74655668,\n",
              "        0.33126129, 0.54058014, 0.26028086, 0.63582291, 0.49420149]),\n",
              " 'W2': array([[-2.53770423, -3.41020128, -2.28586382, -3.52187379, -1.94746565,\n",
              "         -3.80202652,  3.72193544,  3.6819045 ,  3.50036993,  3.6503617 ],\n",
              "        [ 4.01035383,  4.1969938 ,  2.69647668,  4.42692749,  2.7634962 ,\n",
              "          3.99447626, -2.29317184, -2.64380813, -2.42940192, -2.31167587]]),\n",
              " 'b2': array([0.95552614, 0.44991346])}"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJtYlqEsqct7"
      },
      "outputs": [],
      "source": [
        "Y_pred = []\n",
        "for x in X:\n",
        "    y_pred = list(evaluate(x, parameters, sigmoid, softmax))\n",
        "    Y_pred.append(y_pred)\n",
        "Y_pred = np.array(Y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXn67QtrqptM",
        "outputId": "fe4d499c-ba46-4008-f5fd-d259ebe12de1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[1.06046168e-06, 9.99998940e-01],\n",
              "        [9.99996379e-01, 3.62106986e-06],\n",
              "        [7.16625520e-07, 9.99999283e-01],\n",
              "        [9.99999647e-01, 3.52673575e-07],\n",
              "        [3.49575888e-06, 9.99996504e-01],\n",
              "        [9.99998245e-01, 1.75539432e-06],\n",
              "        [2.44181581e-07, 9.99999756e-01],\n",
              "        [9.99999870e-01, 1.29693404e-07],\n",
              "        [7.91537154e-07, 9.99999208e-01],\n",
              "        [9.99999282e-01, 7.17695289e-07]]),\n",
              " array([[0., 1.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 0.]]))"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_pred, y_one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHx8bbtKrwWb",
        "outputId": "7a04b372-5cc7-4fc7-a75b-10b624b1eaa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "for i in Y_pred:\n",
        "    print(i.argmax())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
